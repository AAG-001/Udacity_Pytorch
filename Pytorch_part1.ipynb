{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch_part1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AAG-001/Udacity_Pytorch/blob/master/Pytorch_part1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7M5emkL3exwr",
        "colab_type": "text"
      },
      "source": [
        "Lesson 5 starting with pytorch part 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYHtdnR6ewO0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkqEkyPofOIp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def activation(x):\n",
        "  #Sigmoid activation function\n",
        "  return 1/(1+torch.exp(-x))\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8IRgs8SgjdA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "4b6a530f-fe16-40c4-bd9c-872ed7e42ff2"
      },
      "source": [
        "torch.manual_seed(7)    #setting random seed\n",
        "\n",
        "# 5 random normal variables\n",
        "features=torch.randn((1,5))\n",
        "\n",
        "#defining random weights similar to features\n",
        "weights=torch.randn_like(features)\n",
        "\n",
        "#defining bias\n",
        "bias=torch.randn(1,1)\n",
        "\n",
        "#print(features)\n",
        "#print (weights)\n",
        "#print(bias)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.1468,  0.7861,  0.9468, -1.1143,  1.6908]])\n",
            "tensor([[-0.8948, -0.3556,  1.2324,  0.1382, -1.6822]])\n",
            "tensor([[0.3177]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xn4PY6Mci7nW",
        "colab_type": "text"
      },
      "source": [
        "Calculationg output of tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Tfun5zXi3f3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7c3cdd0d-c80b-45b4-adbf-cc03f094a04d"
      },
      "source": [
        "\"\"\"\n",
        "#reshaping weights for matrix multiplication\n",
        "weights.reshape(5,1)\n",
        "#print(weights.reshape(5,1))\n",
        "\"\"\"\n",
        "\n",
        "matrix_mul=torch.mm(features,weights.reshape(5,1))\n",
        "#print(\"matrix multiplication\",matrix_mul)\n",
        "\n",
        "Bsum=(matrix_mul+bias)\n",
        "print(\"matrix multiplication + bias :\",Bsum)\n",
        "\n",
        "#passing Bsum to activation function\n",
        "activation(Bsum)\n",
        "\n",
        "#print(features*weights)\n",
        "#print(torch.sum(features*weights))\n",
        "\n",
        "\n",
        "activation(torch.sum(features*weights)+bias)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "matrix multiplication + bias : tensor([[-1.6619]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1595]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJ2kXRDzP6bF",
        "colab_type": "text"
      },
      "source": [
        "Multilayer network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnQDPNuoQANj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Generate some data\n",
        "torch.manual_seed(7) # Set the random seed so things are predictable\n",
        "\n",
        "# Features are 3 random normal variables\n",
        "features = torch.randn((1, 3))\n",
        "\n",
        "# Define the size of each layer in our network\n",
        "n_input = features.shape[1]     # Number of input units, must match number of input features\n",
        "n_hidden = 2                    # Number of hidden units \n",
        "n_output = 1                    # Number of output units\n",
        "\n",
        "# Weights for inputs to hidden layer\n",
        "W1 = torch.randn(n_input, n_hidden)\n",
        "# Weights for hidden layer to output layer\n",
        "W2 = torch.randn(n_hidden, n_output)\n",
        "\n",
        "# and bias terms for hidden and output layers\n",
        "B1 = torch.randn((1, n_hidden))\n",
        "B2 = torch.randn((1, n_output))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixM2XW_fRJIc",
        "colab_type": "text"
      },
      "source": [
        "Printing all variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDjoZz26QbN9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "05116f9f-ac6b-48db-be43-731fc82a4599"
      },
      "source": [
        "print(features)\n",
        "print(n_input)\n",
        "print(W1)\n",
        "print(W2)\n",
        "print(B1)\n",
        "print(B2)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.1468,  0.7861,  0.9468]])\n",
            "3\n",
            "tensor([[-1.1143,  1.6908],\n",
            "        [-0.8948, -0.3556],\n",
            "        [ 1.2324,  0.1382]])\n",
            "tensor([[-1.6822],\n",
            "        [ 0.3177]])\n",
            "tensor([[0.1328, 0.1373]])\n",
            "tensor([[0.2405]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iZ8EJjtRfAJ",
        "colab_type": "text"
      },
      "source": [
        "Making a multilayer network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-5vH92TRQEC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "de4b6461-39d3-4f67-c5ad-e325d1235640"
      },
      "source": [
        "h=activation(torch.mm(features,W1)+B1)\n",
        "print(activation(torch.mm(h,W2)+B2))\n",
        "\n",
        "print(activation(torch.mm(activation(torch.mm(features,W1)+B1),W2)+B2))"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.3171]])\n",
            "tensor([[0.3171]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhY9kcm1WpK3",
        "colab_type": "text"
      },
      "source": [
        "Number of hidden units(h in this case) a parameter of the network are called as hyperparameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBseD04dYNRU",
        "colab_type": "text"
      },
      "source": [
        "Note: While using numpy array we can convert it to tensors and vica versa.\n",
        "They both share same memory, hence coputation done on one will be reflected on the other one too."
      ]
    }
  ]
}